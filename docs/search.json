[
  {
    "objectID": "posts/challenge1_instructions.html",
    "href": "posts/challenge1_instructions.html",
    "title": "Challenge 1 Instructions",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge1_instructions.html#challenge-overview",
    "href": "posts/challenge1_instructions.html#challenge-overview",
    "title": "Challenge 1 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to\n\nread in a dataset, and\ndescribe the dataset using both words and any supporting information (e.g., tables, etc)"
  },
  {
    "objectID": "posts/challenge1_instructions.html#read-in-the-data",
    "href": "posts/challenge1_instructions.html#read-in-the-data",
    "title": "Challenge 1 Instructions",
    "section": "Read in the Data",
    "text": "Read in the Data\nRead in one (or more) of the following data sets, using the correct R package and command.\nYou should have already downloaded the datasets from Google Classroom and stored them in a common directory on your computer.\nIn this challenge, as in all subsequent challenges, the number of stars corresponds to the difficulty of the dataset. You are only required to do the challenge on one dataset, though you are welcome to do it with multiple datasets.\nIn general, I encourage you to “challenge” yourself by trying to work with a dataset above your experience.\n\nrailroad_2012_clean_county.csv ⭐\nbirds.csv ⭐⭐\nFAOstat\\*.csv ⭐⭐\nwild_bird_data.xlsx ⭐⭐⭐\nStateCounty2012.xls ⭐⭐⭐⭐\n\nAdd any comments or documentation as needed. More challenging data sets may require additional code chunks and documentation."
  },
  {
    "objectID": "posts/challenge1_instructions.html#describe-the-data",
    "href": "posts/challenge1_instructions.html#describe-the-data",
    "title": "Challenge 1 Instructions",
    "section": "Describe the data",
    "text": "Describe the data\nUsing a combination of words and results of R commands, can you provide a high level description of the data? Describe as efficiently as possible where/how the data was (likely) gathered, indicate the cases and variables (both the interpretation and any details you deem useful to the reader to fully understand your chosen data)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS 601: Data Science Fundamentals",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 15, 2024\n\n\nChallenge 1 Instructions\n\n\nSean Conway\n\n\n\n\nDec 18, 2023\n\n\nData Import\n\n\nSean Conway\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog contains challenges, solutions, and demonstration scripts for DACSS 601."
  },
  {
    "objectID": "posts/example-data_import.html",
    "href": "posts/example-data_import.html",
    "title": "Data Import",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE)\nlibrary(dplyr)\nlibrary(here)\nlibrary(readxl)\nlibrary(readr)"
  },
  {
    "objectID": "posts/example-data_import.html#overview",
    "href": "posts/example-data_import.html#overview",
    "title": "Data Import",
    "section": "Overview",
    "text": "Overview\nToday, we’re going to read in three versions of the poultry_tidy data. These data are available on the Google Classroom.\nWe will specifically read in 3 data files:\n- poultry_tidy.csv\n- poultry_tidy.xlsx\n- poultry_tidy.RData\nThese are the “clean” versions of the raw data files.\nTo run this file, all 3 datasets should be in the same directory on your computer.\nOn my computer, I have all datasets stored in a folder named _data.\nI also use the here package to manage relative directories."
  },
  {
    "objectID": "posts/example-data_import.html#getting-started",
    "href": "posts/example-data_import.html#getting-started",
    "title": "Data Import",
    "section": "Getting Started",
    "text": "Getting Started\nTo begin, we need to load two packages: readr and readxl, which contain very useful functions for reading in data to `R.\n\nlibrary(readxl)\n\nIf you’re unsure whether or not you have these packages installed, you can run the following command:\n\ninstalled.packages()\n\nWe’re now ready to get started reading in actual datasets."
  },
  {
    "objectID": "posts/example-data_import.html#reading-in-delimited-text-files",
    "href": "posts/example-data_import.html#reading-in-delimited-text-files",
    "title": "Data Import",
    "section": "Reading in delimited text files",
    "text": "Reading in delimited text files\n.csv is a common type of delimited text file. .csv stands for comma-separated value. This means that commas separate cells from one another.\nR has a base read.csv() function. However, it comes with a couple of downsides - namely that it imports data as a dataframe rather than a tibble. So we will be using the function read_csv() from the readr package. In addition to importing data as a tibble, it also does a much better job guessing data types.\nread_csv() is essentially a wrapper function (a function that calls another function) around the more general read_delim() function. Also see read_tsv() for tab-separated values.\n\n?read_delim\n\nLet’s look at the data files available for us to read in:\n\nlist.files(here(\"posts\",\"_data\"))\n\n [1] \"AB_NYC_2019.csv\"                                                                                 \n [2] \"abc_poll_2021.csv\"                                                                               \n [3] \"ActiveDuty_MaritalStatus.xls\"                                                                    \n [4] \"animal_weight.csv\"                                                                               \n [5] \"australian_marriage_law_postal_survey_2017_-_response_final.xls\"                                 \n [6] \"australian_marriage_tidy.csv\"                                                                    \n [7] \"birds.csv\"                                                                                       \n [8] \"cereal.csv\"                                                                                      \n [9] \"co2_data.txt\"                                                                                    \n[10] \"cwc.csv\"                                                                                         \n[11] \"Data_Extract_From_World_Development_Indicators.xlsx\"                                             \n[12] \"Data_Extract_FromWorld Development Indicators.xlsx\"                                              \n[13] \"debt_in_trillions.xlsx\"                                                                          \n[14] \"DS0001\"                                                                                          \n[15] \"eggs_tidy.csv\"                                                                                   \n[16] \"emissions.csv\"                                                                                   \n[17] \"End of the Semester Report Fall 2022.csv\"                                                        \n[18] \"FAOSTAT_cattle_dairy.csv\"                                                                        \n[19] \"FAOSTAT_country_groups.csv\"                                                                      \n[20] \"FAOSTAT_egg_chicken.csv\"                                                                         \n[21] \"FAOSTAT_livestock.csv\"                                                                           \n[22] \"FedFundsRate.csv\"                                                                                \n[23] \"FRBNY-SCE-Public-Microdata-Complete-13-16.xlsx\"                                                  \n[24] \"hotel_bookings.csv\"                                                                              \n[25] \"NBA_Player_Stats.csv\"                                                                            \n[26] \"online_retail.csv\"                                                                               \n[27] \"organiceggpoultry.xls\"                                                                           \n[28] \"poultry_tidy.csv\"                                                                                \n[29] \"poultry_tidy.RData\"                                                                              \n[30] \"poultry_tidy.xlsx\"                                                                               \n[31] \"Public_School_Characteristics_2017-18.csv\"                                                       \n[32] \"railroad_2012_clean_county.csv\"                                                                  \n[33] \"sce-labor-chart-data-public.xlsx\"                                                                \n[34] \"snl_actors.csv\"                                                                                  \n[35] \"snl_casts.csv\"                                                                                   \n[36] \"snl_seasons.csv\"                                                                                 \n[37] \"starwars1.RData\"                                                                                 \n[38] \"StateCounty2012.xls\"                                                                             \n[39] \"test_objs.RData\"                                                                                 \n[40] \"Total_cost_for_top_15_pathogens_2018.xlsx\"                                                       \n[41] \"USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx\"\n[42] \"wild_bird_data.xlsx\"                                                                             \n\n\nThere’s a lot of data files there, but we are going to import the poultry_tidy.csv file. Doing so is very simple using read_csv():\n\npoultry_from_csv &lt;- read_csv(here(\"posts\",\"_data\",\"poultry_tidy.csv\"))\n\nRows: 600 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Product, Month\ndbl (2): Year, Price_Dollar\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s take a look at our dataset (to view the tibble, running the name of the object will print it to the console):\n\npoultry_from_csv\n\n\n\n  \n\n\nhead(poultry_from_csv)\n\n\n\n  \n\n\n\nIt worked great! The data is all there. To inspect the data types for each of the four columns in poultry_from_csv, we can use spec() or typeof():\n\npoultry_from_csv &lt;- read_csv(here(\"posts\",\"_data\",\"poultry_tidy.csv\"))\n\n\nspec(poultry_from_csv) # use the spec() function to check the data type for your columns\n\ncols(\n  Product = col_character(),\n  Year = col_double(),\n  Month = col_character(),\n  Price_Dollar = col_double()\n)\n\n# can also use typeof() function on individual columns\ntypeof(poultry_from_csv$Product)\n\n[1] \"character\"\n\ntypeof(poultry_from_csv$Year)\n\n[1] \"double\"\n\ntypeof(poultry_from_csv$Month)\n\n[1] \"character\"\n\ntypeof(poultry_from_csv$Price_Dollar)\n\n[1] \"double\"\n\n\nSee this R section below for some more info on read_delim():\n\n# read_delim() has a number of optional arguments\nargs(read_delim)\n\nfunction (file, delim = NULL, quote = \"\\\"\", escape_backslash = FALSE, \n    escape_double = TRUE, col_names = TRUE, col_types = NULL, \n    col_select = NULL, id = NULL, locale = default_locale(), \n    na = c(\"\", \"NA\"), quoted_na = TRUE, comment = \"\", trim_ws = FALSE, \n    skip = 0, n_max = Inf, guess_max = min(1000, n_max), name_repair = \"unique\", \n    num_threads = readr_threads(), progress = show_progress(), \n    show_col_types = should_show_types(), skip_empty_rows = TRUE, \n    lazy = should_read_lazy()) \nNULL\n\n# there's too many to list here, so we will just go over a few\n# run ?read_delim() to learn more\n# 1) delim - text delimiter.\n# default is NULL and read_delim() guesses delimiter\n#\n# 2) quote - symbol telling R when to quote a string\n# default is \"\\\"\"\n# below comes from R documentation on quotes\n# https://stat.ethz.ch/R-manual/R-devel/library/base/html/Quotes.html\n# identical() is a function that returns TRUE if two objects are equal\nidentical(1+4, 3+2)\n\n[1] TRUE\n\nidentical('\"It\\'s alive!\", he screamed.',\n          \"\\\"It's alive!\\\", he screamed.\") # same\n\n[1] TRUE\n\n#\n# 3) escape_backlash\n# use backlash to escape special characters?\n# default = FALSE\n#\n# 4) col_names\n# can be TRUE (default), meaning that R reads in the first row of values as column names\n# can FALSE - R creates column names (x1 x2 etc)\n# OR can be a character vector of custom column names\npoultry_custom_cols &lt;- read_csv(\"_data/poultry_tidy.csv\",\n                                col_names = c(\"prod\",\"yr\",\"mo\",\"$\"),\n                                skip = 1) # need this to skip the file's column names\n\nRows: 600 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): prod, mo\ndbl (2): yr, $\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npoultry_custom_cols\n\n\n\n  \n\n\npoultry_custom_cols$`$` # note the backticks around the $ sign\n\n  [1] 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500\n [10] 2.38500 2.38500 2.38500 7.03750 7.03750 7.03750 7.03750 7.03750 7.03750\n [19] 7.03750 7.03750 7.03750 7.03750 7.03750 7.03750 3.90500 3.90500 3.90500\n [28] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n [37] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n [46] 2.03500 2.03500 2.03500 2.16250 2.16250 2.16250 2.16250 2.16250 2.16250\n [55] 2.16250 2.16250 2.16250 2.16250 2.16250 2.16250 2.35000 2.38500 2.38500\n [64] 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500\n [73] 6.37500 7.00000 7.00000 7.00000 7.00000 7.00000 7.00000 7.00000 7.00000\n [82] 7.00000 7.03750 7.03750 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n [91] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500\n[100] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[109] 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.16250 2.16250\n[118] 2.16250 2.16250 2.16250 2.35000 2.35000 2.35000 2.35000 2.35000 2.35000\n[127] 2.35000 2.35000 2.35000 2.35000 2.35000 2.35000 6.37500 6.37500 6.37500\n[136] 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500\n[145] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[154] 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[163] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.15000 2.15000 2.15000\n[172] 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000\n[181] 2.48000 2.48000 2.48000 2.41500 2.35000 2.35000 2.41500 2.35000 2.35000\n[190] 2.35000 2.35000 2.35000 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[199] 6.45500 6.42300 6.37500 6.37500 6.37500 6.37500 3.90500 3.90500 3.90500\n[208] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[217] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[226] 2.03500 2.03500 2.03500 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[235] 2.22000 2.19200 2.15000 2.15000 2.15000 2.15000 2.48000 2.48000 2.48000\n[244] 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000\n[253] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[262] 6.45500 6.45500 6.45500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[271] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500\n[280] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[289] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[298] 2.22000 2.22000 2.22000 2.20500 2.20500 2.20500 2.20500 2.20500 2.48000\n[307] 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 6.45500 6.45500 6.45500\n[316] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[325] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[334] 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[343] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.22000 2.22000 2.22000\n[352] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[361] 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500\n[370] 2.20500 2.20500 2.20500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[379] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 3.90500 3.90500 3.90500\n[388] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[397] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[406] 2.03500 2.03500 2.03500 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[415] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.17000 2.17000 2.19625\n[424] 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500\n[433] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[442] 6.45500 6.45500 6.45500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[451] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500\n[460] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[469] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[478] 2.22000 2.22000 2.22000 2.17000 2.17000 2.17000 2.17000 2.17000 2.17000\n[487] 2.17000 2.17000 2.17000 2.17000 2.17000 2.17000 6.44000 6.45500 6.45500\n[496] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[505] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[514] 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[523] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.13000 2.22000 2.22000\n[532] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[541] 1.97500 1.97500 2.09000 2.12000 2.14500 2.16375 2.17000 2.17000 2.17000\n[550] 2.17000 2.17000 2.17000 6.45500 6.42500 6.42500 6.42500 6.42500 6.41000\n[559] 6.42500 6.42500 6.42500 6.42500 6.42500 6.42500      NA      NA      NA\n[568]      NA      NA      NA 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[577] 1.93500 1.93500 1.93500 1.93500 1.93500 2.01875 2.03500 2.03500 2.03500\n[586] 2.03500 2.03500 2.03500      NA 2.03000 2.03000 2.03000 2.03000 2.00375\n[595] 1.99500 1.99500 1.99500 1.99500 1.99500 1.99500\n\n# $ is a \"special symbol\" in R, because it is an operator used for indexing\n# $ is technically an illegal column name, but we can still use it with ``\n# same goes for column names consisting of numbers or other symbols, etc.\n#\n# 5) col_types\n# default=NULL\n# if NULL R guesses data type from first 1000 rows\n# can also specify manually (but be careful)\n# see ?read_delim and scroll to col_types for details\n#\n# 6) skip\n# number of lines to skip\n# default=0\n# can be very useful with messy data files\n#\n# 7) n_max\n# maximum number of lines to read\n# default=Inf\n#\n#"
  },
  {
    "objectID": "posts/example-data_import.html#read-in-.xls.xlsx-files",
    "href": "posts/example-data_import.html#read-in-.xls.xlsx-files",
    "title": "Data Import",
    "section": "Read in .xls/.xlsx files",
    "text": "Read in .xls/.xlsx files\n.xls and .xlsx are files created in Microsoft Excel. There are separate functions read_xls() and read_xlsx(), but I find it’s best to use the wrapper function read_excel(). This will automatically call the correct function and avoid an error from accidentally mis-specifying the file type.\nSee below for what happens if we call the wrong function for the file type:\n\n# the try() function will try to run the code\n# see tryCatch() for more error handling \n# this code doesn't work because it tries to read the wrong file type\ntry(read_xls(here(\"posts\",\"_data\",\"poultry_tidy.xlsx\")))\n\nError : \n  filepath: /Users/seanconway/Github/DACSS_601_W24/posts/_data/poultry_tidy.xlsx\n  libxls error: Unable to open file\n\n\nThe code below works just fine, however:\n\n# this code works \npoultry_from_excel &lt;- try(read_excel(here(\"posts\",\"_data\",\"poultry_tidy.xlsx\"),\n                                     skip = 5,\n                                     col_names = c(\"prod\",\"year\",\"month\",\"price\"))) \npoultry_from_excel \n\n\n\n  \n\n\n\nLet’s take a look at this tibble:\n\n# examining our tibble\nhead(poultry_from_excel) # view the first several rows\n\n\n\n  \n\n\ncolnames(poultry_from_excel) # print column names\n\n[1] \"prod\"  \"year\"  \"month\" \"price\"\n\nglimpse(poultry_from_excel) # tidy little summary of it\n\nRows: 596\nColumns: 4\n$ prod  &lt;chr&gt; \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"…\n$ year  &lt;dbl&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n$ month &lt;chr&gt; \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"Novemb…\n$ price &lt;dbl&gt; 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, …\n\n# the package::function() syntax is only necessary if the package isn't loaded\n\nFunction documentation:\n\n# to view function documentation\n?read_excel\n\n# optional arguments\n# 1) sheet=NULL\n# number of the sheet to read in\n# by default it reads the first sheet\n\n# 2) range=NULL\n# range of cells to read in\n# uses the cellranger package to work with specific cells in Excel files\n# for more, see the cellranger package\n# https://cran.r-project.org/web/packages/cellranger/index.html\n\n# 3) col_names=TRUE\n# how to get column names (works the same as read_delim())\n\n# 4) col_types=NULL\n# types of data in columns (works the same as read_delim())\n\n# 5) skip = 0\n# number of lines to skip (works the same as read_delim())\n\n# 6) n_max=Inf\n# max lines to read (works the same as read_delim())"
  },
  {
    "objectID": "posts/example-data_import.html#reading-in-.rdata-files",
    "href": "posts/example-data_import.html#reading-in-.rdata-files",
    "title": "Data Import",
    "section": "Reading in .RData Files",
    "text": "Reading in .RData Files\nReading .RData is less commonly needed, but it’s still important to know about. .RData is a file type exclusively associated with R. It’s commonly used when someone has performed operations with data and saved the results to give to collaborators.\nWe can use the load() function to load R objects into our R environment from a file:\n\n# running the load() function on the data file name will load the objects into your R environment\nload(here(\"posts\",\"_data\",\"poultry_tidy.RData\"))\npoultry_tidy\n\n\n\n  \n\n\n# there's now a poultry_tidy object in our R environment\n\nNote that we do not assign the data file to an object. Rather, it comes in as an object based on whatever the previous user named it as. If we try to assign it as an object, the object will only have the name of the data file, rather than the data itself:\n\n# note that this operation shouldn't include any variable assignment\ntest_dat &lt;- load(here(\"posts\",\"_data\",\"poultry_tidy.RData\"))\ntest_dat # now it contains the object name, not the object itself\n\n[1] \"poultry_tidy\"\n\n\nYou can also save any number of R objects to a .RData file using the save() function:\n\na &lt;- rnorm(1000)\nb &lt;- matrix(runif(100),nrow=50,ncol=2)\nc &lt;- as_tibble(mtcars)\nsave(a,b,c,file=here(\"posts\",\"_data\",\"test_objs.RData\"))\n# there is now a test_objs.RData file in my working directory: \nlist.files(here(\"posts\",\"_data/\"))\n\n [1] \"AB_NYC_2019.csv\"                                                                                 \n [2] \"abc_poll_2021.csv\"                                                                               \n [3] \"ActiveDuty_MaritalStatus.xls\"                                                                    \n [4] \"animal_weight.csv\"                                                                               \n [5] \"australian_marriage_law_postal_survey_2017_-_response_final.xls\"                                 \n [6] \"australian_marriage_tidy.csv\"                                                                    \n [7] \"birds.csv\"                                                                                       \n [8] \"cereal.csv\"                                                                                      \n [9] \"co2_data.txt\"                                                                                    \n[10] \"cwc.csv\"                                                                                         \n[11] \"Data_Extract_From_World_Development_Indicators.xlsx\"                                             \n[12] \"Data_Extract_FromWorld Development Indicators.xlsx\"                                              \n[13] \"debt_in_trillions.xlsx\"                                                                          \n[14] \"DS0001\"                                                                                          \n[15] \"eggs_tidy.csv\"                                                                                   \n[16] \"emissions.csv\"                                                                                   \n[17] \"End of the Semester Report Fall 2022.csv\"                                                        \n[18] \"FAOSTAT_cattle_dairy.csv\"                                                                        \n[19] \"FAOSTAT_country_groups.csv\"                                                                      \n[20] \"FAOSTAT_egg_chicken.csv\"                                                                         \n[21] \"FAOSTAT_livestock.csv\"                                                                           \n[22] \"FedFundsRate.csv\"                                                                                \n[23] \"FRBNY-SCE-Public-Microdata-Complete-13-16.xlsx\"                                                  \n[24] \"hotel_bookings.csv\"                                                                              \n[25] \"NBA_Player_Stats.csv\"                                                                            \n[26] \"online_retail.csv\"                                                                               \n[27] \"organiceggpoultry.xls\"                                                                           \n[28] \"poultry_tidy.csv\"                                                                                \n[29] \"poultry_tidy.RData\"                                                                              \n[30] \"poultry_tidy.xlsx\"                                                                               \n[31] \"Public_School_Characteristics_2017-18.csv\"                                                       \n[32] \"railroad_2012_clean_county.csv\"                                                                  \n[33] \"sce-labor-chart-data-public.xlsx\"                                                                \n[34] \"snl_actors.csv\"                                                                                  \n[35] \"snl_casts.csv\"                                                                                   \n[36] \"snl_seasons.csv\"                                                                                 \n[37] \"starwars1.RData\"                                                                                 \n[38] \"StateCounty2012.xls\"                                                                             \n[39] \"test_objs.RData\"                                                                                 \n[40] \"Total_cost_for_top_15_pathogens_2018.xlsx\"                                                       \n[41] \"USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx\"\n[42] \"wild_bird_data.xlsx\"                                                                             \n\n\nLet’s remove these objects from our R environment and re-load them from the file we saved:\n\n# remove objects from environment\nrm(list=c(\"a\",\"b\",\"c\"))\n\n# now they're back! (If you save them)\ntry(load(here(\"posts\",\"_data\",\"test_objs.RData\")))"
  },
  {
    "objectID": "posts/example-data_import.html#conclusion",
    "href": "posts/example-data_import.html#conclusion",
    "title": "Data Import",
    "section": "Conclusion",
    "text": "Conclusion\nYou now know a little bit about how to read in some common data types. Note that these aren’t the only types of data you’ll encounter, but they are by far the most common ones."
  },
  {
    "objectID": "tmp.html",
    "href": "tmp.html",
    "title": "Challenge 1",
    "section": "",
    "text": "1+1\n\n[1] 2\n\n\nThis is my challenge."
  }
]
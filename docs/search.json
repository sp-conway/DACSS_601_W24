[
  {
    "objectID": "posts/challenge1_instructions.html",
    "href": "posts/challenge1_instructions.html",
    "title": "Challenge 1 Instructions",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge1_instructions.html#challenge-overview",
    "href": "posts/challenge1_instructions.html#challenge-overview",
    "title": "Challenge 1 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to\n\nread in a dataset, and\ndescribe the dataset using both words and any supporting information (e.g., tables, etc)"
  },
  {
    "objectID": "posts/challenge1_instructions.html#read-in-the-data",
    "href": "posts/challenge1_instructions.html#read-in-the-data",
    "title": "Challenge 1 Instructions",
    "section": "Read in the Data",
    "text": "Read in the Data\nRead in one (or more) of the following data sets, using the correct R package and command.\nYou should have already downloaded the datasets from Google Classroom and stored them in a common directory on your computer.\nIn this challenge, as in all subsequent challenges, the number of stars corresponds to the difficulty of the dataset. You are only required to do the challenge on one dataset, though you are welcome to do it with multiple datasets.\nIn general, I encourage you to “challenge” yourself by trying to work with a dataset above your experience.\n\nrailroad_2012_clean_county.csv ⭐\nbirds.csv ⭐⭐\nFAOstat\\*.csv ⭐⭐\nwild_bird_data.xlsx ⭐⭐⭐\nStateCounty2012.xls ⭐⭐⭐⭐\n\nAdd any comments or documentation as needed. More challenging data sets may require additional code chunks and documentation."
  },
  {
    "objectID": "posts/challenge1_instructions.html#describe-the-data",
    "href": "posts/challenge1_instructions.html#describe-the-data",
    "title": "Challenge 1 Instructions",
    "section": "Describe the data",
    "text": "Describe the data\nUsing a combination of words and results of R commands, can you provide a high level description of the data? Describe as efficiently as possible where/how the data was (likely) gathered, indicate the cases and variables (both the interpretation and any details you deem useful to the reader to fully understand your chosen data)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS 601: Data Science Fundamentals",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 15, 2024\n\n\nChallenge 1 Instructions\n\n\nSean Conway\n\n\n\n\nDec 20, 2023\n\n\ngroup_by() & summarise()\n\n\nSean Conway\n\n\n\n\nDec 18, 2023\n\n\nData Import\n\n\nSean Conway\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog contains challenges, solutions, and demonstration scripts for DACSS 601."
  },
  {
    "objectID": "posts/example-data_import.html",
    "href": "posts/example-data_import.html",
    "title": "Data Import",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE)\nlibrary(dplyr)\nlibrary(here)\nlibrary(readxl)\nlibrary(readr)"
  },
  {
    "objectID": "posts/example-data_import.html#overview",
    "href": "posts/example-data_import.html#overview",
    "title": "Data Import",
    "section": "Overview",
    "text": "Overview\nToday, we’re going to read in three versions of the poultry_tidy data. These data are available on the Google Classroom.\nWe will specifically read in 3 data files:\n- poultry_tidy.csv\n- poultry_tidy.xlsx\n- poultry_tidy.RData\nThese are the “clean” versions of the raw data files.\nTo run this file, all 3 datasets should be in the same directory on your computer.\nOn my computer, I have all datasets stored in a folder named _data.\nI also use the here package to manage relative directories."
  },
  {
    "objectID": "posts/example-data_import.html#getting-started",
    "href": "posts/example-data_import.html#getting-started",
    "title": "Data Import",
    "section": "Getting Started",
    "text": "Getting Started\nTo begin, we need to load two packages: readr and readxl, which contain very useful functions for reading in data to `R.\n\nlibrary(readxl)\n\nIf you’re unsure whether or not you have these packages installed, you can run the following command:\n\ninstalled.packages()\n\nWe’re now ready to get started reading in actual datasets."
  },
  {
    "objectID": "posts/example-data_import.html#reading-in-delimited-text-files",
    "href": "posts/example-data_import.html#reading-in-delimited-text-files",
    "title": "Data Import",
    "section": "Reading in delimited text files",
    "text": "Reading in delimited text files\n.csv is a common type of delimited text file. .csv stands for comma-separated value. This means that commas separate cells from one another.\nR has a base read.csv() function. However, it comes with a couple of downsides - namely that it imports data as a dataframe rather than a tibble. So we will be using the function read_csv() from the readr package. In addition to importing data as a tibble, it also does a much better job guessing data types.\nread_csv() is essentially a wrapper function (a function that calls another function) around the more general read_delim() function. Also see read_tsv() for tab-separated values.\n\n?read_delim\n\nLet’s look at the data files available for us to read in:\n\nlist.files(here(\"posts\",\"_data\"))\n\n [1] \"AB_NYC_2019.csv\"                                                                                 \n [2] \"abc_poll_2021.csv\"                                                                               \n [3] \"ActiveDuty_MaritalStatus.xls\"                                                                    \n [4] \"animal_weight.csv\"                                                                               \n [5] \"australian_marriage_law_postal_survey_2017_-_response_final.xls\"                                 \n [6] \"australian_marriage_tidy.csv\"                                                                    \n [7] \"birds.csv\"                                                                                       \n [8] \"cereal.csv\"                                                                                      \n [9] \"co2_data.txt\"                                                                                    \n[10] \"cwc.csv\"                                                                                         \n[11] \"Data_Extract_From_World_Development_Indicators.xlsx\"                                             \n[12] \"Data_Extract_FromWorld Development Indicators.xlsx\"                                              \n[13] \"debt_in_trillions.xlsx\"                                                                          \n[14] \"DS0001\"                                                                                          \n[15] \"eggs_tidy.csv\"                                                                                   \n[16] \"emissions.csv\"                                                                                   \n[17] \"End of the Semester Report Fall 2022.csv\"                                                        \n[18] \"FAOSTAT_cattle_dairy.csv\"                                                                        \n[19] \"FAOSTAT_country_groups.csv\"                                                                      \n[20] \"FAOSTAT_egg_chicken.csv\"                                                                         \n[21] \"FAOSTAT_livestock.csv\"                                                                           \n[22] \"FedFundsRate.csv\"                                                                                \n[23] \"FRBNY-SCE-Public-Microdata-Complete-13-16.xlsx\"                                                  \n[24] \"hotel_bookings.csv\"                                                                              \n[25] \"NBA_Player_Stats.csv\"                                                                            \n[26] \"online_retail.csv\"                                                                               \n[27] \"organiceggpoultry.xls\"                                                                           \n[28] \"poultry_tidy.csv\"                                                                                \n[29] \"poultry_tidy.RData\"                                                                              \n[30] \"poultry_tidy.xlsx\"                                                                               \n[31] \"Public_School_Characteristics_2017-18.csv\"                                                       \n[32] \"railroad_2012_clean_county.csv\"                                                                  \n[33] \"sce-labor-chart-data-public.xlsx\"                                                                \n[34] \"snl_actors.csv\"                                                                                  \n[35] \"snl_casts.csv\"                                                                                   \n[36] \"snl_seasons.csv\"                                                                                 \n[37] \"starwars1.RData\"                                                                                 \n[38] \"StateCounty2012.xls\"                                                                             \n[39] \"test_objs.RData\"                                                                                 \n[40] \"Total_cost_for_top_15_pathogens_2018.xlsx\"                                                       \n[41] \"USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx\"\n[42] \"wild_bird_data.xlsx\"                                                                             \n\n\nThere’s a lot of data files there, but we are going to import the poultry_tidy.csv file. Doing so is very simple using read_csv():\n\npoultry_from_csv &lt;- read_csv(here(\"posts\",\"_data\",\"poultry_tidy.csv\"))\n\nRows: 600 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Product, Month\ndbl (2): Year, Price_Dollar\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s take a look at our dataset (to view the tibble, running the name of the object will print it to the console):\n\npoultry_from_csv\n\n\n\n  \n\n\nhead(poultry_from_csv)\n\n\n\n  \n\n\n\nIt worked great! The data is all there. To inspect the data types for each of the four columns in poultry_from_csv, we can use spec() or typeof():\n\npoultry_from_csv &lt;- read_csv(here(\"posts\",\"_data\",\"poultry_tidy.csv\"))\n\n\nspec(poultry_from_csv) # use the spec() function to check the data type for your columns\n\ncols(\n  Product = col_character(),\n  Year = col_double(),\n  Month = col_character(),\n  Price_Dollar = col_double()\n)\n\n# can also use typeof() function on individual columns\ntypeof(poultry_from_csv$Product)\n\n[1] \"character\"\n\ntypeof(poultry_from_csv$Year)\n\n[1] \"double\"\n\ntypeof(poultry_from_csv$Month)\n\n[1] \"character\"\n\ntypeof(poultry_from_csv$Price_Dollar)\n\n[1] \"double\"\n\n\nSee this R section below for some more info on read_delim():\n\n# read_delim() has a number of optional arguments\nargs(read_delim)\n\nfunction (file, delim = NULL, quote = \"\\\"\", escape_backslash = FALSE, \n    escape_double = TRUE, col_names = TRUE, col_types = NULL, \n    col_select = NULL, id = NULL, locale = default_locale(), \n    na = c(\"\", \"NA\"), quoted_na = TRUE, comment = \"\", trim_ws = FALSE, \n    skip = 0, n_max = Inf, guess_max = min(1000, n_max), name_repair = \"unique\", \n    num_threads = readr_threads(), progress = show_progress(), \n    show_col_types = should_show_types(), skip_empty_rows = TRUE, \n    lazy = should_read_lazy()) \nNULL\n\n# there's too many to list here, so we will just go over a few\n# run ?read_delim() to learn more\n# 1) delim - text delimiter.\n# default is NULL and read_delim() guesses delimiter\n#\n# 2) quote - symbol telling R when to quote a string\n# default is \"\\\"\"\n# below comes from R documentation on quotes\n# https://stat.ethz.ch/R-manual/R-devel/library/base/html/Quotes.html\n# identical() is a function that returns TRUE if two objects are equal\nidentical(1+4, 3+2)\n\n[1] TRUE\n\nidentical('\"It\\'s alive!\", he screamed.',\n          \"\\\"It's alive!\\\", he screamed.\") # same\n\n[1] TRUE\n\n#\n# 3) escape_backlash\n# use backlash to escape special characters?\n# default = FALSE\n#\n# 4) col_names\n# can be TRUE (default), meaning that R reads in the first row of values as column names\n# can FALSE - R creates column names (x1 x2 etc)\n# OR can be a character vector of custom column names\npoultry_custom_cols &lt;- read_csv(\"_data/poultry_tidy.csv\",\n                                col_names = c(\"prod\",\"yr\",\"mo\",\"$\"),\n                                skip = 1) # need this to skip the file's column names\n\nRows: 600 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): prod, mo\ndbl (2): yr, $\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npoultry_custom_cols\n\n\n\n  \n\n\npoultry_custom_cols$`$` # note the backticks around the $ sign\n\n  [1] 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500\n [10] 2.38500 2.38500 2.38500 7.03750 7.03750 7.03750 7.03750 7.03750 7.03750\n [19] 7.03750 7.03750 7.03750 7.03750 7.03750 7.03750 3.90500 3.90500 3.90500\n [28] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n [37] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n [46] 2.03500 2.03500 2.03500 2.16250 2.16250 2.16250 2.16250 2.16250 2.16250\n [55] 2.16250 2.16250 2.16250 2.16250 2.16250 2.16250 2.35000 2.38500 2.38500\n [64] 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500 2.38500\n [73] 6.37500 7.00000 7.00000 7.00000 7.00000 7.00000 7.00000 7.00000 7.00000\n [82] 7.00000 7.03750 7.03750 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n [91] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500\n[100] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[109] 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.16250 2.16250\n[118] 2.16250 2.16250 2.16250 2.35000 2.35000 2.35000 2.35000 2.35000 2.35000\n[127] 2.35000 2.35000 2.35000 2.35000 2.35000 2.35000 6.37500 6.37500 6.37500\n[136] 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500 6.37500\n[145] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[154] 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[163] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.15000 2.15000 2.15000\n[172] 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000 2.15000\n[181] 2.48000 2.48000 2.48000 2.41500 2.35000 2.35000 2.41500 2.35000 2.35000\n[190] 2.35000 2.35000 2.35000 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[199] 6.45500 6.42300 6.37500 6.37500 6.37500 6.37500 3.90500 3.90500 3.90500\n[208] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[217] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[226] 2.03500 2.03500 2.03500 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[235] 2.22000 2.19200 2.15000 2.15000 2.15000 2.15000 2.48000 2.48000 2.48000\n[244] 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000\n[253] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[262] 6.45500 6.45500 6.45500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[271] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500\n[280] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[289] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[298] 2.22000 2.22000 2.22000 2.20500 2.20500 2.20500 2.20500 2.20500 2.48000\n[307] 2.48000 2.48000 2.48000 2.48000 2.48000 2.48000 6.45500 6.45500 6.45500\n[316] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[325] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[334] 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[343] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.22000 2.22000 2.22000\n[352] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[361] 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500\n[370] 2.20500 2.20500 2.20500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[379] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 3.90500 3.90500 3.90500\n[388] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[397] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[406] 2.03500 2.03500 2.03500 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[415] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.17000 2.17000 2.19625\n[424] 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500 2.20500\n[433] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[442] 6.45500 6.45500 6.45500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[451] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500\n[460] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[469] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[478] 2.22000 2.22000 2.22000 2.17000 2.17000 2.17000 2.17000 2.17000 2.17000\n[487] 2.17000 2.17000 2.17000 2.17000 2.17000 2.17000 6.44000 6.45500 6.45500\n[496] 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500 6.45500\n[505] 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[514] 3.90500 3.90500 3.90500 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500\n[523] 2.03500 2.03500 2.03500 2.03500 2.03500 2.03500 2.13000 2.22000 2.22000\n[532] 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000 2.22000\n[541] 1.97500 1.97500 2.09000 2.12000 2.14500 2.16375 2.17000 2.17000 2.17000\n[550] 2.17000 2.17000 2.17000 6.45500 6.42500 6.42500 6.42500 6.42500 6.41000\n[559] 6.42500 6.42500 6.42500 6.42500 6.42500 6.42500      NA      NA      NA\n[568]      NA      NA      NA 3.90500 3.90500 3.90500 3.90500 3.90500 3.90500\n[577] 1.93500 1.93500 1.93500 1.93500 1.93500 2.01875 2.03500 2.03500 2.03500\n[586] 2.03500 2.03500 2.03500      NA 2.03000 2.03000 2.03000 2.03000 2.00375\n[595] 1.99500 1.99500 1.99500 1.99500 1.99500 1.99500\n\n# $ is a \"special symbol\" in R, because it is an operator used for indexing\n# $ is technically an illegal column name, but we can still use it with ``\n# same goes for column names consisting of numbers or other symbols, etc.\n#\n# 5) col_types\n# default=NULL\n# if NULL R guesses data type from first 1000 rows\n# can also specify manually (but be careful)\n# see ?read_delim and scroll to col_types for details\n#\n# 6) skip\n# number of lines to skip\n# default=0\n# can be very useful with messy data files\n#\n# 7) n_max\n# maximum number of lines to read\n# default=Inf\n#\n#"
  },
  {
    "objectID": "posts/example-data_import.html#read-in-.xls.xlsx-files",
    "href": "posts/example-data_import.html#read-in-.xls.xlsx-files",
    "title": "Data Import",
    "section": "Read in .xls/.xlsx files",
    "text": "Read in .xls/.xlsx files\n.xls and .xlsx are files created in Microsoft Excel. There are separate functions read_xls() and read_xlsx(), but I find it’s best to use the wrapper function read_excel(). This will automatically call the correct function and avoid an error from accidentally mis-specifying the file type.\nSee below for what happens if we call the wrong function for the file type:\n\n# the try() function will try to run the code\n# see tryCatch() for more error handling \n# this code doesn't work because it tries to read the wrong file type\ntry(read_xls(here(\"posts\",\"_data\",\"poultry_tidy.xlsx\")))\n\nError : \n  filepath: /Users/seanconway/Github/DACSS_601_W24/posts/_data/poultry_tidy.xlsx\n  libxls error: Unable to open file\n\n\nThe code below works just fine, however:\n\n# this code works \npoultry_from_excel &lt;- try(read_excel(here(\"posts\",\"_data\",\"poultry_tidy.xlsx\"),\n                                     skip = 5,\n                                     col_names = c(\"prod\",\"year\",\"month\",\"price\"))) \npoultry_from_excel \n\n\n\n  \n\n\n\nLet’s take a look at this tibble:\n\n# examining our tibble\nhead(poultry_from_excel) # view the first several rows\n\n\n\n  \n\n\ncolnames(poultry_from_excel) # print column names\n\n[1] \"prod\"  \"year\"  \"month\" \"price\"\n\nglimpse(poultry_from_excel) # tidy little summary of it\n\nRows: 596\nColumns: 4\n$ prod  &lt;chr&gt; \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"Whole\", \"…\n$ year  &lt;dbl&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n$ month &lt;chr&gt; \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"Novemb…\n$ price &lt;dbl&gt; 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, 2.3850, …\n\n# the package::function() syntax is only necessary if the package isn't loaded\n\nFunction documentation:\n\n# to view function documentation\n?read_excel\n\n# optional arguments\n# 1) sheet=NULL\n# number of the sheet to read in\n# by default it reads the first sheet\n\n# 2) range=NULL\n# range of cells to read in\n# uses the cellranger package to work with specific cells in Excel files\n# for more, see the cellranger package\n# https://cran.r-project.org/web/packages/cellranger/index.html\n\n# 3) col_names=TRUE\n# how to get column names (works the same as read_delim())\n\n# 4) col_types=NULL\n# types of data in columns (works the same as read_delim())\n\n# 5) skip = 0\n# number of lines to skip (works the same as read_delim())\n\n# 6) n_max=Inf\n# max lines to read (works the same as read_delim())"
  },
  {
    "objectID": "posts/example-data_import.html#reading-in-.rdata-files",
    "href": "posts/example-data_import.html#reading-in-.rdata-files",
    "title": "Data Import",
    "section": "Reading in .RData Files",
    "text": "Reading in .RData Files\nReading .RData is less commonly needed, but it’s still important to know about. .RData is a file type exclusively associated with R. It’s commonly used when someone has performed operations with data and saved the results to give to collaborators.\nWe can use the load() function to load R objects into our R environment from a file:\n\n# running the load() function on the data file name will load the objects into your R environment\nload(here(\"posts\",\"_data\",\"poultry_tidy.RData\"))\npoultry_tidy\n\n\n\n  \n\n\n# there's now a poultry_tidy object in our R environment\n\nNote that we do not assign the data file to an object. Rather, it comes in as an object based on whatever the previous user named it as. If we try to assign it as an object, the object will only have the name of the data file, rather than the data itself:\n\n# note that this operation shouldn't include any variable assignment\ntest_dat &lt;- load(here(\"posts\",\"_data\",\"poultry_tidy.RData\"))\ntest_dat # now it contains the object name, not the object itself\n\n[1] \"poultry_tidy\"\n\n\nYou can also save any number of R objects to a .RData file using the save() function:\n\na &lt;- rnorm(1000)\nb &lt;- matrix(runif(100),nrow=50,ncol=2)\nc &lt;- as_tibble(mtcars)\nsave(a,b,c,file=here(\"posts\",\"_data\",\"test_objs.RData\"))\n# there is now a test_objs.RData file in my working directory: \nlist.files(here(\"posts\",\"_data/\"))\n\n [1] \"AB_NYC_2019.csv\"                                                                                 \n [2] \"abc_poll_2021.csv\"                                                                               \n [3] \"ActiveDuty_MaritalStatus.xls\"                                                                    \n [4] \"animal_weight.csv\"                                                                               \n [5] \"australian_marriage_law_postal_survey_2017_-_response_final.xls\"                                 \n [6] \"australian_marriage_tidy.csv\"                                                                    \n [7] \"birds.csv\"                                                                                       \n [8] \"cereal.csv\"                                                                                      \n [9] \"co2_data.txt\"                                                                                    \n[10] \"cwc.csv\"                                                                                         \n[11] \"Data_Extract_From_World_Development_Indicators.xlsx\"                                             \n[12] \"Data_Extract_FromWorld Development Indicators.xlsx\"                                              \n[13] \"debt_in_trillions.xlsx\"                                                                          \n[14] \"DS0001\"                                                                                          \n[15] \"eggs_tidy.csv\"                                                                                   \n[16] \"emissions.csv\"                                                                                   \n[17] \"End of the Semester Report Fall 2022.csv\"                                                        \n[18] \"FAOSTAT_cattle_dairy.csv\"                                                                        \n[19] \"FAOSTAT_country_groups.csv\"                                                                      \n[20] \"FAOSTAT_egg_chicken.csv\"                                                                         \n[21] \"FAOSTAT_livestock.csv\"                                                                           \n[22] \"FedFundsRate.csv\"                                                                                \n[23] \"FRBNY-SCE-Public-Microdata-Complete-13-16.xlsx\"                                                  \n[24] \"hotel_bookings.csv\"                                                                              \n[25] \"NBA_Player_Stats.csv\"                                                                            \n[26] \"online_retail.csv\"                                                                               \n[27] \"organiceggpoultry.xls\"                                                                           \n[28] \"poultry_tidy.csv\"                                                                                \n[29] \"poultry_tidy.RData\"                                                                              \n[30] \"poultry_tidy.xlsx\"                                                                               \n[31] \"Public_School_Characteristics_2017-18.csv\"                                                       \n[32] \"railroad_2012_clean_county.csv\"                                                                  \n[33] \"sce-labor-chart-data-public.xlsx\"                                                                \n[34] \"snl_actors.csv\"                                                                                  \n[35] \"snl_casts.csv\"                                                                                   \n[36] \"snl_seasons.csv\"                                                                                 \n[37] \"starwars1.RData\"                                                                                 \n[38] \"StateCounty2012.xls\"                                                                             \n[39] \"test_objs.RData\"                                                                                 \n[40] \"Total_cost_for_top_15_pathogens_2018.xlsx\"                                                       \n[41] \"USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx\"\n[42] \"wild_bird_data.xlsx\"                                                                             \n\n\nLet’s remove these objects from our R environment and re-load them from the file we saved:\n\n# remove objects from environment\nrm(list=c(\"a\",\"b\",\"c\"))\n\n# now they're back! (If you save them)\ntry(load(here(\"posts\",\"_data\",\"test_objs.RData\")))"
  },
  {
    "objectID": "posts/example-data_import.html#conclusion",
    "href": "posts/example-data_import.html#conclusion",
    "title": "Data Import",
    "section": "Conclusion",
    "text": "Conclusion\nYou now know a little bit about how to read in some common data types. Note that these aren’t the only types of data you’ll encounter, but they are by far the most common ones."
  },
  {
    "objectID": "tmp.html",
    "href": "tmp.html",
    "title": "Challenge 1",
    "section": "",
    "text": "1+1\n\n[1] 2\n\n\nThis is my challenge."
  },
  {
    "objectID": "posts/example-groupby_summarize.html",
    "href": "posts/example-groupby_summarize.html",
    "title": "group_by() & summarise()",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE)\nlibrary(dplyr)\nlibrary(here)\nlibrary(readr)"
  },
  {
    "objectID": "posts/example-groupby_summarize.html#overview",
    "href": "posts/example-groupby_summarize.html#overview",
    "title": "group_by() & summarise()",
    "section": "Overview",
    "text": "Overview\nToday, we’re going to read in the poultry_tidy data and use group_by(), mutate(), summarise() to perform simple operations. We will also discuss the use of the pipe (%&gt;%) as a way to streamline data operations."
  },
  {
    "objectID": "posts/example-groupby_summarize.html#importing-the-data",
    "href": "posts/example-groupby_summarize.html#importing-the-data",
    "title": "group_by() & summarise()",
    "section": "Importing the data",
    "text": "Importing the data\n\npoultry &lt;- read_csv(here(\"posts\",\"_data\",\"poultry_tidy.csv\"))\n\nRows: 600 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Product, Month\ndbl (2): Year, Price_Dollar\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npoultry"
  },
  {
    "objectID": "posts/example-groupby_summarize.html#summarisesummarize",
    "href": "posts/example-groupby_summarize.html#summarisesummarize",
    "title": "group_by() & summarise()",
    "section": "Summarise/Summarize",
    "text": "Summarise/Summarize\nsummarise() is a function that allows you to perform multiple data summaries at once. It is one of several “workhorse” functions from the dplyr package, which we will use quite a bit this term. Note that you can also use summarize(), and it will work just the same.\nFor example, imagine we want to you use the mean() function to calculate the average price of poultry in our dataset. However, we also want to calculate the standard deviation (using sd()) to get a sense of the variability in our data. Standard deviation is a measure of how much the values in a variable differ from the average.\nIn Base R, we would need to do this in two separate lines.\n\nmean(poultry$Price_Dollar,na.rm=T) # there are some NA values we need to ignore\n\n[1] 3.390472\n\nsd(poultry$Price_Dollar,na.rm=T)\n\n[1] 1.731353\n\n\nUsing summarise(), we can calculate both of these at once, and without using the $ syntax. That is, dplyr uses something called “data masking” to make working with variables in a tibble/data frame easier (this is sort of an advanced topic that I’ll gloss over for now, but see this link if you would like to learn more).\n\nsummarise(poultry,\n          mean_price=mean(Price_Dollar,na.rm=T),\n          sd_price=sd(Price_Dollar,na.rm=T))\n\n\n\n  \n\n\n\nThis is handy because it creates a nice looking table for us. Notice that I was even allowed to give my “new” variables custom names. Without this, the column names will default to the code used to create them and it can look kind of ugly.\n\nsummarise(poultry,\n          mean(Price_Dollar,na.rm=T),\n          sd(Price_Dollar,na.rm=T))\n\n\n\n  \n\n\n\nI can use many different functions within summarise() .Really any function that allows me to distill a variable down to a single value, including median, variance, etc.\n\nsummarise(poultry,\n          mean_price=mean(Price_Dollar,na.rm=T),\n          median_price=median(Price_Dollar,na.rm=T),\n          var_price=var(Price_Dollar,na.rm=T),\n          sd_price=sd(Price_Dollar,na.rm=T))\n\n\n\n  \n\n\n\nHere we can see that the mean_price is higher than the median_price. You haven’t yet gotten to the stats tutorials, but this suggests that there are some relatively high priced products that are driving the mean price up. The median will be fairly robust to these types of values, so it’s a bit lower."
  },
  {
    "objectID": "posts/example-groupby_summarize.html#mutate",
    "href": "posts/example-groupby_summarize.html#mutate",
    "title": "group_by() & summarise()",
    "section": "mutate()",
    "text": "mutate()\nIn addition to summarise(), there’s another workhorse function used for creating new columns: mutate().\nImagine we want to convert price from dollars to cents1. We can do so, using the mutate() function, which adds a new column to an existing data frame.2 Below we tell the mutate() function to create a new column, within the poultry data frame, called Price_Cents, which is computed as the price in dollars multiplied by 100.\n\nmutate(poultry, Price_Cents=Price_Dollar*100)\n\n\n\n  \n\n\n\nWe now see a new column, called Price_Cents, that is indeed Price_Dollar multiplied by 100.\nHowever, if I run the line below to take another look at the poultry, Price_Cents is gone.\n\npoultry\n\n\n\n  \n\n\n\nThis is because we only ran that line of code creating the column. We didn’t actually store it as an object3 in our environment. To do so, we need to use the &lt;- operator. &lt;- is also called the assignment operator, because it assigns R objects specific names. Generally speaking, &lt;- creates a new object in your environment. We are going to call our new tibble poultry_1\n\npoultry_1 &lt;- mutate(poultry, Price_Cents=Price_Dollar*100)\n\nTo take a look at this new data frame, we will just run the name as a separate line of code.\n\npoultry_1\n\n\n\n  \n\n\n\nNow we see Price_Cents stored as a column.\nWe’re going to move on to group_by() , where we’ll discuss creating groups within a dataframe. We won’t use poultry_1 any more, because Price_Cents is redundant with Price_Dollar, and cents is probably less informative tha dollar to most people. However, mutate() is a powerful tool (and an alternative to the base R $ syntax) for creating new variables in a data frame."
  },
  {
    "objectID": "posts/example-groupby_summarize.html#group_by",
    "href": "posts/example-groupby_summarize.html#group_by",
    "title": "group_by() & summarise()",
    "section": "group_by()",
    "text": "group_by()\nOften we don’t just care about a single numerical summary of a variable - rather, we want to know how that variable changes (or remains constant) across another, categorical variable. For example, we may want to know how salary changes by gender or ethnicity, or how carbon emissions change by state.\ngroup_by() allows us to create “groups” in the data based on one or more variables (referred to as grouping variables). We can then use summarise() to calculate separate summary statistics for each group.\nBelow, I use group_by() to tell R that I want to take the poultry dataset and group by the column Product. Then, I pass this grouped data frame to summarise(), where I again compute the mean price.\n\nsummarise(group_by(poultry, Product),\n          mean_price=mean(Price_Dollar,na.rm=T))\n\n\n\n  \n\n\n\nIt appears that boneless skinless breasts are by far the most expensive poultry product within this dataset."
  },
  {
    "objectID": "posts/example-groupby_summarize.html#pipes",
    "href": "posts/example-groupby_summarize.html#pipes",
    "title": "group_by() & summarise()",
    "section": "Pipes",
    "text": "Pipes\nYou might have noticed that the above operation using group_by() and summarise() looked a little clunky. We wrapped the group_by code within the summarise function, and it was a bit hard to read.\nThere’s a way around this, however! We can use the pipe operator (%&gt;%) to streamline our operations. The pipe allows us to pass a take a tibble/data frame and perform multiple intermediate operations on it, passing the modified data frame through on each step.\n\npoultry %&gt;%\n  group_by(Product) %&gt;%\n  summarise(mean_price=mean(Price_Dollar,na.rm=T))\n\n\n\n  \n\n\n\nVoila!\nLet’s break that down a bit. First, I entered poultry, the name of the tibble I was working with. I then used the pipe, to pass poultry through to the group_by() function, where I created groups based on the column Product. If I run just these first two lines, we can see that poultry looks the same, but R now tells us that there are 5 groups present, based on the variable Product.\n\npoultry %&gt;%\n  group_by(Product)\n\n\n\n  \n\n\n\nFinally, after we group by Product, we can then pass this through to the summarise function using a pipe, where we compute the mean price in the same way as before.\n\npoultry %&gt;%\n  group_by(Product) %&gt;%\n  summarise(mean_price=mean(Price_Dollar,na.rm=T))\n\n\n\n  \n\n\n\nThe pipe is a powerful tool that we will use quite a bit in this class. It does take some getting used to, and I don’t expect it to click right away. With practice, however, you will become proficient at using it."
  },
  {
    "objectID": "posts/example-groupby_summarize.html#conclusion",
    "href": "posts/example-groupby_summarize.html#conclusion",
    "title": "group_by() & summarise()",
    "section": "Conclusion",
    "text": "Conclusion\nNow you’ve learned a little bit about how to summarize data, and in particular how to use group_by() to summarize it based on a grouping variable. We also learned how to create new columns within an existing data frame."
  },
  {
    "objectID": "posts/example-groupby_summarize.html#footnotes",
    "href": "posts/example-groupby_summarize.html#footnotes",
    "title": "group_by() & summarise()",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m not actually sure why you would want to do so. This is just an example of how to use mutate().↩︎\nmutate() can also modify an existing column, but we won’t be using it for that here.↩︎\nAn object is a generic term for any variable in your R environment.↩︎"
  }
]